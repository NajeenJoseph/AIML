{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIML_R8_Project1_Word_Embeddings_with_DNN_&_Chatbot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-XI9Vj1N_JV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "420a9a71-70f2-4981-d41b-01d76fe7d0c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPutmZVbAstE",
        "outputId": "9c6f0dda-6321-407f-e183-91434dd845c2"
      },
      "source": [
        "import warnings\n",
        "import os\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import seaborn as sns\n",
        "import tensorflow \n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zoxvxC2AswS"
      },
      "source": [
        "# suppress display of warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# display all dataframe columns\n",
        "pd.options.display.max_columns = None\n",
        "\n",
        "# to set the limit to 3 decimals\n",
        "pd.options.display.float_format = '{:.7f}'.format\n",
        "\n",
        "# display all dataframe rows\n",
        "pd.options.display.max_rows = None"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9q-nfx4AsyH"
      },
      "source": [
        "blog = pd.read_csv('/content/drive/MyDrive/Dataset - blogtext.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "lLMALu0SAs0u",
        "outputId": "2e6efcdf-c2fe-4b74-d7f1-078010b3be21"
      },
      "source": [
        "blog.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>date</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>14,May,2004</td>\n",
              "      <td>Info has been found (+/- 100 pages,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>13,May,2004</td>\n",
              "      <td>These are the team members:   Drewe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>In het kader van kernfusie op aarde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2059027</td>\n",
              "      <td>male</td>\n",
              "      <td>15</td>\n",
              "      <td>Student</td>\n",
              "      <td>Leo</td>\n",
              "      <td>12,May,2004</td>\n",
              "      <td>testing!!!  testing!!!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>11,June,2004</td>\n",
              "      <td>Thanks to Yahoo!'s Toolbar I can ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>I had an interesting conversation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>Somehow Coca-Cola has a way of su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>If anything, Korea is a country o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>10,June,2004</td>\n",
              "      <td>Take a read of this news article ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3581210</td>\n",
              "      <td>male</td>\n",
              "      <td>33</td>\n",
              "      <td>InvestmentBanking</td>\n",
              "      <td>Aquarius</td>\n",
              "      <td>09,June,2004</td>\n",
              "      <td>I surf the English news sites a l...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id gender  age              topic      sign          date  \\\n",
              "0  2059027   male   15            Student       Leo   14,May,2004   \n",
              "1  2059027   male   15            Student       Leo   13,May,2004   \n",
              "2  2059027   male   15            Student       Leo   12,May,2004   \n",
              "3  2059027   male   15            Student       Leo   12,May,2004   \n",
              "4  3581210   male   33  InvestmentBanking  Aquarius  11,June,2004   \n",
              "5  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
              "6  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
              "7  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
              "8  3581210   male   33  InvestmentBanking  Aquarius  10,June,2004   \n",
              "9  3581210   male   33  InvestmentBanking  Aquarius  09,June,2004   \n",
              "\n",
              "                                                text  \n",
              "0             Info has been found (+/- 100 pages,...  \n",
              "1             These are the team members:   Drewe...  \n",
              "2             In het kader van kernfusie op aarde...  \n",
              "3                   testing!!!  testing!!!            \n",
              "4               Thanks to Yahoo!'s Toolbar I can ...  \n",
              "5               I had an interesting conversation...  \n",
              "6               Somehow Coca-Cola has a way of su...  \n",
              "7               If anything, Korea is a country o...  \n",
              "8               Take a read of this news article ...  \n",
              "9               I surf the English news sites a l...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 381
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEJ1dnScAs3O"
      },
      "source": [
        "blog['age_group'] = blog['age'].apply(lambda x: '30s' if x>28 else ('10s' if x<20 else '20s'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkZ5ARF_As5r"
      },
      "source": [
        "blog.drop('age',axis=1, inplace= True)## dropping the age column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvV_uuBWAs8d"
      },
      "source": [
        "blog_df= blog.sample(100000, random_state=2).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMn2jxANZIp_"
      },
      "source": [
        "## removing unnecessary columns which are blogger id, date:\n",
        "\n",
        "blog_df.drop(['id','date'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVYKoxpBeM1e"
      },
      "source": [
        "blog_df[\"target\"] = blog_df.apply(lambda x : [x[\"gender\"],x[\"age_group\"],x[\"topic\"],x[\"sign\"]],axis =1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVu53YMgZI4p"
      },
      "source": [
        "blog_df['len'] = blog_df['text'].apply(lambda x: len(x.split())) ## calculating the length of each row"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjGhsXipWQcJ"
      },
      "source": [
        "ind = blog_df[blog_df['len']==0].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjIu0ltJWb-X"
      },
      "source": [
        "blog_df.drop(index = ind, axis=0, inplace =True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1_FGMYgYHQG",
        "outputId": "35f0d12c-1864-482e-de18-5477ad29e782"
      },
      "source": [
        "blog_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99534, 7)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ4w2ARwNOZ8"
      },
      "source": [
        "##Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LcqNTziONvP0"
      },
      "source": [
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kP6VAPcLNXGi"
      },
      "source": [
        "blog_df['text'] = blog_df['text'].apply(lambda x: str(x).lower()) ## converting to lower case"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVAAzwoiNXJW"
      },
      "source": [
        "blog_df['text'] = blog_df['text'].apply(lambda x: re.sub(r'https?:\\/\\/.\\S+', \" \",x)) ## removes the http: links"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKOk8C-tNXMC",
        "outputId": "f43b2912-0185-4782-f933-9e4877d3395c"
      },
      "source": [
        "print(blog_df['text'][2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       i woke up very early on saturday morning, more early than i’d have hoped on a day off. i was planning on going to the beach, set up my chair and read some scripts for work and do some of my own work. i was going to a party late in the afternoon, so i wanted to get as much work in as possible so i could enjoy myself without feeling guilty. but since i had woken up at 5 in the morning, it was too dark and too chilly to head to the beach right away. and the fork in the road at the end of sunset canyon that leads onto the pch is tempting to someone like me, who adores the coastline here and is mystified by the landscape that spreads north of los angeles. if i had turned left then i would’ve been in santa monica and eventually in the marina. but if i turned right, then i’d be driving through malibu and beyond. i love what’s beyond malibu – every bit of it. so i turned right.   the pch is beautiful at five-thirty or six in the morning. the ocean smells the best at that time and there are basically no cars on the road. i recommend listening to jazz when you make the drive at that hour. once i drove the 27 miles that is malibu, i got off on hueneme road and drove through oxnard and ventura county. i decided i would head into santa barbara before coming back. i would have gone so far as big sur and possibly the monterey peninsula, but i don’t like to rush that trip. and there wasn’t enough time to do it anyway, since i had to be at a party and i was still a bit worried about not accomplishing any work. soon though, as i wove my way down the pch, i stopped stressing about losing those hours to work. i stopped in for a coffee someplace in ventura county, by the naval base, called the friends café. the coffee was a little weak but there was something nice about the place. the people that sat outside eating their omelettes and drinking their weak coffee were not like the people in la who crowd the sidewalks for weekend brunch. they weren’t like the hipsters in los feliz with their egg whites and their power fruit salads. these people seemed unaffected. they seemed happy. if i wasn’t on a schedule i might have stayed but i ordered my coffee to go instead and i got back in the car. i made my way to the border of santa barbara by about ten fifteen or ten-thirty. i drove around a while and started to head back the other way – back to the place i was from. before i left i ordered another coffee, this time from starbucks. i had gone through a couple of cds on my trip – a jazz cd and then a willie nelson cd. on the way back to los angeles though i listened to santa barbara and ventura’s npr station, which was pleasant because they didn’t seem to have as many people on the radio with faux british accents. a woman was interviewing a travel writer who was based in santa barbara and divided his time between his home there and japan. he was telling listeners that they should look at the place they live as though they were foreigners, so they could see it differently, as though they had new eyes. i think there’s a lot of weight to a philosophy like that.  i made it back to la around two o’clock. i took unfamiliar roads home and i got a bit lost, but i didn’t mind. when i got to marina del rey i went swimming in the ocean before getting ready for the party. i saved my work for sunday and got quite a lot done. i was thinking a lot more clearly, even though i still had seawater in my ears. next weekend i think i’ll go swimming again before i begin working on my application for the stegner.            \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGd6ek3XNXOT"
      },
      "source": [
        "blog_df['text']= blog_df['text'].apply(lambda x: re.sub(r\"\\b[^\\s]+@[^\\s]+[.][^\\s]+\\b\", \" \",x)) ## removing email id's"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12a1JSLVOqew"
      },
      "source": [
        "blog_df['text'] = blog_df['text'].replace('urlLink',' ',regex=True) ## removing the word urlLink"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyvp-36NOqhP"
      },
      "source": [
        "blog_df['text'] = blog_df['text'].apply(lambda x: re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''', \" \", x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03CZkQa0PKek"
      },
      "source": [
        "**Removing short forms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn872UAGOqj6"
      },
      "source": [
        "def short_form(text):\n",
        "  text = re.sub(r\"what's\", \"what is \", text)\n",
        "  text = re.sub(r\"\\'s\", \" \", text)\n",
        "  text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "  text = re.sub(r\"can't\", \"can not \", text)\n",
        "  text = re.sub(r\"n't\", \" not \", text)\n",
        "  text = re.sub(r\"i'm\", \"i am \", text)\n",
        "  text = re.sub(r\"\\'re\", \" are \", text)\n",
        "  text = re.sub(r\"\\'d\", \" would \", text)\n",
        "  text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "  text = re.sub(r\"youll\", \" you will \", text)\n",
        "  text = re.sub(r\"theyll\", \" they will \", text)\n",
        "  text = re.sub(r\"youve\", \" you have \", text)\n",
        "  text = re.sub(r\"theyve\", \" they have \", text)\n",
        "  text = re.sub(r\"cant\", \"can not \", text)\n",
        "  text = re.sub(r\"youre\", \"you are\", text)\n",
        "  text = re.sub(r\"yup\", \"yes\", text)\n",
        "  text = re.sub(r\"ohh\", \" \", text)\n",
        "  text = re.sub(r\"ahh\", \" \", text)\n",
        "  text = re.sub(r\"ahhh\", \" \", text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFhxn5rfO8bl"
      },
      "source": [
        "blog_df['text'] = blog_df['text'].apply(lambda x: short_form(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ZzExoySrO8iK",
        "outputId": "b105d90e-837f-4d21-9a2e-6729ab7f0252"
      },
      "source": [
        "blog_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>text</th>\n",
              "      <th>age_group</th>\n",
              "      <th>target</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Government</td>\n",
              "      <td>Pisces</td>\n",
              "      <td>the incompetence of transport plann...</td>\n",
              "      <td>30s</td>\n",
              "      <td>[male, 30s, Government, Pisces]</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>male</td>\n",
              "      <td>Student</td>\n",
              "      <td>Libra</td>\n",
              "      <td>2/10/04   one more week till hun...</td>\n",
              "      <td>10s</td>\n",
              "      <td>[male, 10s, Student, Libra]</td>\n",
              "      <td>766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Aries</td>\n",
              "      <td>i woke up very early on saturday mornin...</td>\n",
              "      <td>20s</td>\n",
              "      <td>[female, 20s, indUnk, Aries]</td>\n",
              "      <td>692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Leo</td>\n",
              "      <td>ok, lots more pictures!   urllink m...</td>\n",
              "      <td>20s</td>\n",
              "      <td>[male, 20s, Technology, Leo]</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Aries</td>\n",
              "      <td>happy birthday, mom!   today is ...</td>\n",
              "      <td>30s</td>\n",
              "      <td>[male, 30s, indUnk, Aries]</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender       topic    sign  \\\n",
              "0    male  Government  Pisces   \n",
              "1    male     Student   Libra   \n",
              "2  female      indUnk   Aries   \n",
              "3    male  Technology     Leo   \n",
              "4    male      indUnk   Aries   \n",
              "\n",
              "                                                text age_group  \\\n",
              "0             the incompetence of transport plann...       30s   \n",
              "1                2/10/04   one more week till hun...       10s   \n",
              "2         i woke up very early on saturday mornin...       20s   \n",
              "3             ok, lots more pictures!   urllink m...       20s   \n",
              "4                happy birthday, mom!   today is ...       30s   \n",
              "\n",
              "                            target  len  \n",
              "0  [male, 30s, Government, Pisces]  354  \n",
              "1      [male, 10s, Student, Libra]  766  \n",
              "2     [female, 20s, indUnk, Aries]  692  \n",
              "3     [male, 20s, Technology, Leo]   23  \n",
              "4       [male, 30s, indUnk, Aries]   92  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 400
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNj9axN3Pgka"
      },
      "source": [
        "**Removing Special Characters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWdqwIrBPfsC"
      },
      "source": [
        "blog_df['text'] = blog_df['text'].replace('[^\\w\\s]',' ',regex= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "nYxQCMbSPeXO",
        "outputId": "61ceea72-182f-4c9e-e09b-4fa84fc4ac57"
      },
      "source": [
        "blog_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gender</th>\n",
              "      <th>topic</th>\n",
              "      <th>sign</th>\n",
              "      <th>text</th>\n",
              "      <th>age_group</th>\n",
              "      <th>target</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>male</td>\n",
              "      <td>Government</td>\n",
              "      <td>Pisces</td>\n",
              "      <td>the incompetence of transport plann...</td>\n",
              "      <td>30s</td>\n",
              "      <td>[male, 30s, Government, Pisces]</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>male</td>\n",
              "      <td>Student</td>\n",
              "      <td>Libra</td>\n",
              "      <td>2 10 04   one more week till hun...</td>\n",
              "      <td>10s</td>\n",
              "      <td>[male, 10s, Student, Libra]</td>\n",
              "      <td>766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>female</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Aries</td>\n",
              "      <td>i woke up very early on saturday mornin...</td>\n",
              "      <td>20s</td>\n",
              "      <td>[female, 20s, indUnk, Aries]</td>\n",
              "      <td>692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>male</td>\n",
              "      <td>Technology</td>\n",
              "      <td>Leo</td>\n",
              "      <td>ok  lots more pictures    urllink m...</td>\n",
              "      <td>20s</td>\n",
              "      <td>[male, 20s, Technology, Leo]</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>male</td>\n",
              "      <td>indUnk</td>\n",
              "      <td>Aries</td>\n",
              "      <td>happy birthday  mom    today is ...</td>\n",
              "      <td>30s</td>\n",
              "      <td>[male, 30s, indUnk, Aries]</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gender       topic    sign  \\\n",
              "0    male  Government  Pisces   \n",
              "1    male     Student   Libra   \n",
              "2  female      indUnk   Aries   \n",
              "3    male  Technology     Leo   \n",
              "4    male      indUnk   Aries   \n",
              "\n",
              "                                                text age_group  \\\n",
              "0             the incompetence of transport plann...       30s   \n",
              "1                2 10 04   one more week till hun...       10s   \n",
              "2         i woke up very early on saturday mornin...       20s   \n",
              "3             ok  lots more pictures    urllink m...       20s   \n",
              "4                happy birthday  mom    today is ...       30s   \n",
              "\n",
              "                            target  len  \n",
              "0  [male, 30s, Government, Pisces]  354  \n",
              "1      [male, 10s, Student, Libra]  766  \n",
              "2     [female, 20s, indUnk, Aries]  692  \n",
              "3     [male, 20s, Technology, Leo]   23  \n",
              "4       [male, 30s, indUnk, Aries]   92  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 402
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh3Su6JKRaKz"
      },
      "source": [
        "** Removing unnecessary spaces**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdN1cKjiPego"
      },
      "source": [
        "blog_df['text']=  blog_df['text'].str.replace('\\s+',' ',regex = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_XMjZ3pPeje",
        "outputId": "3b8cdb50-d970-4bc4-e14c-3999a861447e"
      },
      "source": [
        "print(blog_df['text'][6])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " another classic from the leader of the free world our enemies are innovative and resourceful and so are we said george bush in an address yesterday they never stop thinking about new ways to harm our country and our people and neither do we this guy should be president \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8Zgm3BReeKv"
      },
      "source": [
        "todo_df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wwJ3sTEZJX5"
      },
      "source": [
        "todo_df= blog_df[['text','target','len']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "zY4NeOrycdt9",
        "outputId": "07a7e4a1-265e-4c32-9da8-49519b016c7e"
      },
      "source": [
        "todo_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the incompetence of transport planners i deal...</td>\n",
              "      <td>[male, 30s, Government, Pisces]</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 10 04 one more week till huntsville yay and...</td>\n",
              "      <td>[male, 10s, Student, Libra]</td>\n",
              "      <td>766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i woke up very early on saturday morning more...</td>\n",
              "      <td>[female, 20s, indUnk, Aries]</td>\n",
              "      <td>692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ok lots more pictures urllink my apartment em...</td>\n",
              "      <td>[male, 20s, Technology, Leo]</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>happy birthday mom today is mom birthday i kn...</td>\n",
              "      <td>[male, 30s, indUnk, Aries]</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0   the incompetence of transport planners i deal...   \n",
              "1   2 10 04 one more week till huntsville yay and...   \n",
              "2   i woke up very early on saturday morning more...   \n",
              "3   ok lots more pictures urllink my apartment em...   \n",
              "4   happy birthday mom today is mom birthday i kn...   \n",
              "\n",
              "                            target  len  \n",
              "0  [male, 30s, Government, Pisces]  354  \n",
              "1      [male, 10s, Student, Libra]  766  \n",
              "2     [female, 20s, indUnk, Aries]  692  \n",
              "3     [male, 20s, Technology, Leo]   23  \n",
              "4       [male, 30s, indUnk, Aries]   92  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p-QxnmYl0Nm",
        "outputId": "2f8b02ca-9975-4165-d0f8-2ff367c77de1"
      },
      "source": [
        "print(todo_df['text'][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " the incompetence of transport planners i deal a lot with public transport in my job and also use it a lot as everyone should this ensures minimal use of the old bmw normally m and i go in to torquay together in the car and i come home on the train because she stays on to do overtime or go to the dentist gym hairdresser while i come home at a reasonable time fridays we normally drive home together as she finishes at 4 15 on a friday a very wise and sensible time to finish if you ask me also one friday in 4 i give a lift to someone to a meeting in the afternoon and then take them home before picking m up which was what was scheduled for today also today m was having her hair done after work so i would have to repark the car after the meeting so she could pick it up and then i would catch the train home unfortunately having parked the car i realised that i didnt have time to walk to the station solution go to the pub and wait for the next train problem did not leave enough time to get to the station so having missed the train with a long wait to the next i decide to head back to town on the bus to catch m with the car these buses are all brand new disabled friendly lowfloor buses that stagecoach have just kindly introduced on a ten minute frequency yeah right 25 minutes later one rolls up followed shortly by another i know it is scientifically explained why buses hunt in twos or even threes but i always have this naive hope that it wont happen to me it would have been easier to take the car or even two cars as we werent coming home together and that is why so many people take their cars and sod the pollution and the congestion if i can not do it properly then who else will the other moral is dont go to the pub if you are waiting for a train andy \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "PasqbbsYcdzM",
        "outputId": "77dcae4c-8105-43de-afbc-f0227cdf66e8"
      },
      "source": [
        "todo_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>99534.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>202.4929974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>376.4966430</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>38.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>114.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>257.0000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>51835.0000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                len\n",
              "count 99534.0000000\n",
              "mean    202.4929974\n",
              "std     376.4966430\n",
              "min       1.0000000\n",
              "25%      38.0000000\n",
              "50%     114.0000000\n",
              "75%     257.0000000\n",
              "max   51835.0000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 409
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qdtq-trcd0e"
      },
      "source": [
        "ina = todo_df[todo_df['len']==0].index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6iXZZmygUbP",
        "outputId": "4f807587-0d06-4f94-c138-eea08952f789"
      },
      "source": [
        "ina"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Int64Index([], dtype='int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 411
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "GQJVZ-gzErxM",
        "outputId": "95aac7b7-c28a-413c-95ff-1a18ec6e0834"
      },
      "source": [
        "todo_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the incompetence of transport planners i deal...</td>\n",
              "      <td>[male, 30s, Government, Pisces]</td>\n",
              "      <td>354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2 10 04 one more week till huntsville yay and...</td>\n",
              "      <td>[male, 10s, Student, Libra]</td>\n",
              "      <td>766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i woke up very early on saturday morning more...</td>\n",
              "      <td>[female, 20s, indUnk, Aries]</td>\n",
              "      <td>692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ok lots more pictures urllink my apartment em...</td>\n",
              "      <td>[male, 20s, Technology, Leo]</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>happy birthday mom today is mom birthday i kn...</td>\n",
              "      <td>[male, 30s, indUnk, Aries]</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  \\\n",
              "0   the incompetence of transport planners i deal...   \n",
              "1   2 10 04 one more week till huntsville yay and...   \n",
              "2   i woke up very early on saturday morning more...   \n",
              "3   ok lots more pictures urllink my apartment em...   \n",
              "4   happy birthday mom today is mom birthday i kn...   \n",
              "\n",
              "                            target  len  \n",
              "0  [male, 30s, Government, Pisces]  354  \n",
              "1      [male, 10s, Student, Libra]  766  \n",
              "2     [female, 20s, indUnk, Aries]  692  \n",
              "3     [male, 20s, Technology, Leo]   23  \n",
              "4       [male, 30s, indUnk, Aries]   92  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McoJ_380gFtS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4248a781-6750-408e-c7f0-afdde815a828"
      },
      "source": [
        "todo_df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text      0\n",
              "target    0\n",
              "len       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 413
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYl6KBvfcd4K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36abc6c5-4a03-4a40-8911-ab9108f66b3b"
      },
      "source": [
        "todo_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99534, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 414
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUhydZF4iM49"
      },
      "source": [
        "##Analyzing and Preparing Data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KD-_HK2iM7R"
      },
      "source": [
        "max_features = 20000\n",
        "maxlen = 100\n",
        "embedding_size = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7uwPr-HiM9s"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words= 15000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQkVpkociNAk"
      },
      "source": [
        "tokenizer.fit_on_texts(list(todo_df['text']))\n",
        "X = tokenizer.texts_to_sequences(todo_df['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYIBcgObZJbB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbadf223-27c1-4eb1-bc20-1a0b79892174"
      },
      "source": [
        "print(\"number of samples:\", len(X))\n",
        "print(X[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 99534\n",
            "[2, 6, 6792, 1, 569, 5, 178, 21, 735, 6792, 9, 12, 281, 4, 126, 283, 7, 5, 178, 31, 202, 129, 22, 6942, 283, 6, 2, 193, 10769, 1749, 328, 4, 1, 63, 9, 3, 332, 9, 2, 291, 4, 1, 146, 133, 17, 2, 1112, 82, 48, 4690, 17, 3, 26, 7324, 43, 63, 3, 2, 4373, 1583, 142, 1, 146, 133, 29, 5, 3900, 54, 6764, 23, 1749, 534, 133, 332, 31, 48, 10071, 29, 204, 553, 17, 5, 414, 5, 108, 2131, 4, 7222, 54, 3, 832, 45, 13, 341, 18, 126, 42, 414, 9, 204, 1, 222, 5, 3098, 3, 176, 3, 5, 801, 9, 2, 723, 4, 57, 137, 79, 133, 140, 2332, 328, 37, 89, 14, 40, 14, 3610, 15, 93, 126, 93, 328, 14, 234, 51, 430, 232, 98, 111, 20, 1, 44, 16, 3, 2, 291, 98, 2, 801, 20, 48, 88, 598, 7, 37, 4, 57, 1, 44, 846, 2, 1112, 133, 1227, 234, 4719, 2, 291, 1, 2929, 8, 1, 631, 16, 54, 3, 479, 3, 2, 1170, 2876, 63, 3, 2, 3513, 4, 335, 15, 2, 163, 1112, 458, 70, 10, 338, 229, 54, 3, 50, 3, 2, 1170, 20, 234, 870, 2, 1112, 21, 5, 147, 335, 3, 2, 163, 1, 1126, 3, 269, 80, 3, 589, 17, 2, 775, 3, 846, 328, 21, 2, 291, 148, 7258, 27, 30, 2060, 110, 8977, 1823, 7258, 8, 16, 34, 7464, 2978, 17, 5, 1008, 873, 8321, 214, 114, 970, 365, 249, 42, 3116, 37, 1517, 3111, 60, 160, 1, 55, 7, 11, 2491, 127, 7258, 3698, 9, 43, 96, 19, 1, 152, 16, 22, 5879, 223, 8, 7, 1246, 494, 3, 18, 7, 44, 16, 76, 1381, 3, 137, 2, 291, 43, 96, 139, 1457, 31, 23, 7182, 353, 133, 332, 4, 8, 11, 127, 20, 167, 71, 137, 92, 1457, 4, 2, 10854, 4, 2, 45, 1, 38, 10, 26, 7, 2563, 57, 67, 257, 32, 2, 95, 2368, 11, 273, 63, 3, 2, 3513, 45, 13, 27, 543, 15, 5, 1112, 2036]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76kWwj3qX8VN"
      },
      "source": [
        "##Padding the sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-icQIIfYQMu"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S38RLUZgYQVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133799ad-2987-48c4-b944-137e560283d9"
      },
      "source": [
        "X = pad_sequences(X , maxlen=maxlen)\n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(99534, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 422
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhDPvTejYQXG"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndG87ozWYQZ0"
      },
      "source": [
        "MB = MultiLabelBinarizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPzjybmTY94d"
      },
      "source": [
        "y = MB.fit_transform(todo_df['target'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzOMFuzMZE2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e03ab6-9381-46ab-bcb6-9bf75196cd1f"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1, ..., 0, 0, 1],\n",
              "       [1, 0, 0, ..., 0, 0, 1],\n",
              "       [0, 1, 0, ..., 1, 1, 0],\n",
              "       ...,\n",
              "       [0, 1, 0, ..., 1, 1, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 1],\n",
              "       [1, 0, 0, ..., 1, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 426
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRYZn3I4ZFwZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd46b394-f3cb-48f9-d235-61002993b054"
      },
      "source": [
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(99534, 100)\n",
            "(99534, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJU3ji5eZFzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dba5be5-a400-4a28-ee4b-4d31289ce640"
      },
      "source": [
        "len(tokenizer.word_index)## total number of words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "230877"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 428
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAGvFunDZF2p"
      },
      "source": [
        "## computing glove embedding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My8y4UwmZF4R"
      },
      "source": [
        "text_file= \"/content/drive/MyDrive/glove.6B.50d.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrYWbVO9Zvxq"
      },
      "source": [
        "embedding = {}\n",
        "for o in open(text_file):\n",
        "  word = o.split(\" \")[0]\n",
        "  emb = o.split(\" \")[1:]\n",
        "  emb = np.asarray(emb, dtype= 'float32')\n",
        "  embedding[word]=emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxaFtd_rZwPH"
      },
      "source": [
        "## Creating weight matrices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ja0Yuo_ZwSE"
      },
      "source": [
        "num_words = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words,50))\n",
        "for word , i in tokenizer.word_index.items():\n",
        "  embedding_vector = embedding.get(word)\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zIxPS12ZwV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abde0870-b868-4b43-89e9-47ceaf8289a0"
      },
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(230878, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 434
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2A5MIeXQaLAT"
      },
      "source": [
        "## Splitting Training and Test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4-BHNxlaLlO"
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size= 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ56JCs1aLn1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da9d43b-5986-4bd2-aad0-30046cf50ec4"
      },
      "source": [
        "print(x_train.shape,y_train.shape)\n",
        "print(x_test.shape,y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(79627, 100) (79627, 57)\n",
            "(19907, 100) (19907, 57)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sw33XJPlaLqe"
      },
      "source": [
        "#Model Building"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg9JAohHaLs6"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_gcTUW8aLva"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, Dropout,BatchNormalization\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Aq77AxaLxy"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(num_words,embedding_size,weights=[embedding_matrix],input_length = maxlen, trainable=False))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(180,activation = 'relu'))\n",
        "model.add(Dense(90,activation = 'relu'))\n",
        "model.add(Dense(64,activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(47,activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(57,activation= 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_WgJQA1aL1m"
      },
      "source": [
        "model.compile(loss = 'binary_crossentropy' , optimizer= 'adam' , metrics = 'accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHwyN3yicOol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45915f69-ac82-47e0-feac-685c86a3abe1"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 50)           11543900  \n",
            "_________________________________________________________________\n",
            "flatten_36 (Flatten)         (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 5000)              20000     \n",
            "_________________________________________________________________\n",
            "dense_111 (Dense)            (None, 180)               900180    \n",
            "_________________________________________________________________\n",
            "dense_112 (Dense)            (None, 90)                16290     \n",
            "_________________________________________________________________\n",
            "dense_113 (Dense)            (None, 64)                5824      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 64)                256       \n",
            "_________________________________________________________________\n",
            "dropout_39 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_114 (Dense)            (None, 47)                3055      \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 47)                188       \n",
            "_________________________________________________________________\n",
            "dropout_40 (Dropout)         (None, 47)                0         \n",
            "_________________________________________________________________\n",
            "dense_115 (Dense)            (None, 57)                2736      \n",
            "=================================================================\n",
            "Total params: 12,492,429\n",
            "Trainable params: 938,307\n",
            "Non-trainable params: 11,554,122\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y25Coc_ncSFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67308d9f-8c0a-4243-c25a-dd3e540cde96"
      },
      "source": [
        "history=model.fit(x_train,y_train,epochs=20,batch_size = 64, validation_data = (x_test,y_test),verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1245/1245 [==============================] - 24s 18ms/step - loss: 0.3844 - accuracy: 0.0935 - val_loss: 0.1693 - val_accuracy: 0.1535\n",
            "Epoch 2/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1706 - accuracy: 0.1810 - val_loss: 0.1687 - val_accuracy: 0.1652\n",
            "Epoch 3/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1684 - accuracy: 0.1875 - val_loss: 0.1687 - val_accuracy: 0.1599\n",
            "Epoch 4/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1656 - accuracy: 0.2122 - val_loss: 0.1690 - val_accuracy: 0.1676\n",
            "Epoch 5/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1615 - accuracy: 0.2258 - val_loss: 0.1711 - val_accuracy: 0.1511\n",
            "Epoch 6/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1561 - accuracy: 0.2293 - val_loss: 0.1757 - val_accuracy: 0.1759\n",
            "Epoch 7/20\n",
            "1245/1245 [==============================] - 22s 18ms/step - loss: 0.1505 - accuracy: 0.2282 - val_loss: 0.1841 - val_accuracy: 0.1927\n",
            "Epoch 8/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1464 - accuracy: 0.2284 - val_loss: 0.1879 - val_accuracy: 0.1428\n",
            "Epoch 9/20\n",
            "1245/1245 [==============================] - 23s 19ms/step - loss: 0.1433 - accuracy: 0.2300 - val_loss: 0.1951 - val_accuracy: 0.1655\n",
            "Epoch 10/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1405 - accuracy: 0.2401 - val_loss: 0.1981 - val_accuracy: 0.1655\n",
            "Epoch 11/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1384 - accuracy: 0.2511 - val_loss: 0.2011 - val_accuracy: 0.1766\n",
            "Epoch 12/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1360 - accuracy: 0.2743 - val_loss: 0.2061 - val_accuracy: 0.1579\n",
            "Epoch 13/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1343 - accuracy: 0.2734 - val_loss: 0.2104 - val_accuracy: 0.1786\n",
            "Epoch 14/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1325 - accuracy: 0.2953 - val_loss: 0.2133 - val_accuracy: 0.2041\n",
            "Epoch 15/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1312 - accuracy: 0.3095 - val_loss: 0.2164 - val_accuracy: 0.1875\n",
            "Epoch 16/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1296 - accuracy: 0.3298 - val_loss: 0.2181 - val_accuracy: 0.1799\n",
            "Epoch 17/20\n",
            "1245/1245 [==============================] - 22s 18ms/step - loss: 0.1306 - accuracy: 0.3113 - val_loss: 0.2221 - val_accuracy: 0.1946\n",
            "Epoch 18/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1273 - accuracy: 0.3424 - val_loss: 0.2235 - val_accuracy: 0.2076\n",
            "Epoch 19/20\n",
            "1245/1245 [==============================] - 23s 19ms/step - loss: 0.1258 - accuracy: 0.3445 - val_loss: 0.2260 - val_accuracy: 0.2067\n",
            "Epoch 20/20\n",
            "1245/1245 [==============================] - 23s 18ms/step - loss: 0.1256 - accuracy: 0.3446 - val_loss: 0.2284 - val_accuracy: 0.2072\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xEiAyCNcpHa"
      },
      "source": [
        "NN = model.predict(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZC8o0oBGthK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb4c56c-44c8-468e-f08a-513fe1d12311"
      },
      "source": [
        "print(NN[0:5].round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWGV2NNNTBHQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c5a85f3-31f5-4ba2-8cf7-3145796f9c42"
      },
      "source": [
        "print(y_test[0:5].round())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgvUj_7rX-4y",
        "outputId": "936320ff-b731-40b7-d297-677dc3b0a3b2"
      },
      "source": [
        "print(classification_report(y_test,NN.round()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.51      0.51      6886\n",
            "           1       0.53      0.54      0.53      9443\n",
            "           2       0.32      0.17      0.22      3578\n",
            "           3       0.00      0.00      0.00       121\n",
            "           4       0.00      0.00      0.00       136\n",
            "           5       0.00      0.00      0.00        34\n",
            "           6       0.00      0.00      0.00      1456\n",
            "           7       0.00      0.00      0.00        49\n",
            "           8       0.00      0.00      0.00      1860\n",
            "           9       0.00      0.00      0.00       966\n",
            "          10       0.00      0.00      0.00        36\n",
            "          11       0.00      0.00      0.00       123\n",
            "          12       0.00      0.00      0.00        66\n",
            "          13       0.00      0.00      0.00       143\n",
            "          14       1.00      0.01      0.02      1963\n",
            "          15       0.00      0.00      0.00      1410\n",
            "          16       0.00      0.00      0.00       117\n",
            "          17       0.00      0.00      0.00       577\n",
            "          18       0.00      0.00      0.00        27\n",
            "          19       0.00      0.00      0.00       190\n",
            "          20       0.00      0.00      0.00       925\n",
            "          21       0.00      0.00      0.00       367\n",
            "          22       0.00      0.00      0.00        12\n",
            "          23       0.00      0.00      0.00       148\n",
            "          24       0.00      0.00      0.00      1555\n",
            "          25       0.00      0.00      0.00       196\n",
            "          26       0.00      0.00      0.00        98\n",
            "          27       0.00      0.00      0.00       460\n",
            "          28       0.00      0.00      0.00        42\n",
            "          29       0.00      0.00      0.00       259\n",
            "          30       0.00      0.00      0.00        55\n",
            "          31       0.00      0.00      0.00      1569\n",
            "          32       0.00      0.00      0.00      1826\n",
            "          33       0.00      0.00      0.00        62\n",
            "          34       0.00      0.00      0.00        12\n",
            "          35       0.00      0.00      0.00       124\n",
            "          36       0.00      0.00      0.00        83\n",
            "          37       0.00      0.00      0.00        93\n",
            "          38       0.00      0.00      0.00       427\n",
            "          39       1.00      0.00      0.00      1659\n",
            "          40       0.00      0.00      0.00       228\n",
            "          41       0.00      0.00      0.00        94\n",
            "          42       0.00      0.00      0.00       128\n",
            "          43       0.00      0.00      0.00      1457\n",
            "          44       0.00      0.00      0.00       199\n",
            "          45       0.00      0.00      0.00      1635\n",
            "          46       0.00      0.00      0.00        71\n",
            "          47       0.32      0.15      0.20      4413\n",
            "          48       0.00      0.00      0.00      1788\n",
            "          49       0.32      0.00      0.01      1234\n",
            "          50       0.00      0.00      0.00       145\n",
            "          51       0.00      0.00      0.00        64\n",
            "          52       1.00      0.03      0.06        62\n",
            "          53       0.00      0.00      0.00      1729\n",
            "          54       0.55      0.64      0.59      9775\n",
            "          55       0.37      0.23      0.28      7321\n",
            "          56       0.59      0.50      0.54     10132\n",
            "\n",
            "   micro avg       0.51      0.29      0.37     79628\n",
            "   macro avg       0.11      0.05      0.05     79628\n",
            "weighted avg       0.37      0.29      0.30     79628\n",
            " samples avg       0.51      0.29      0.36     79628\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IxBlBVISsL-"
      },
      "source": [
        "Inference: \n",
        "\n",
        "*) Totally 57 classes out of which most are highly imbalanced classes.\n",
        "*) Model is overfitting when the increasing the number of epochs. Training accruacy is 34% and test accuracy is 21%.\n",
        "*) Using transfer learning with BERT model, LSTM layers may help us to increase the accuracy."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHlrltiULfu7"
      },
      "source": [
        "#ChatBot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PGQd0wmGLfyU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d98fbb6-654e-489a-fc8b-b3d34878eaee"
      },
      "source": [
        "import nltk\n",
        "import string, random\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEDH-zehLf1F"
      },
      "source": [
        "import json"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYiNnbNINlsi"
      },
      "source": [
        "with open('/content/drive/MyDrive/GL Bot.json') as file:\n",
        "  corpus = json.load(file)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2RaYtKuNlvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ba561c4-885f-4d4e-f3ed-14ff200d6d32"
      },
      "source": [
        "print(corpus)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'intents': [{'tag': 'Intro', 'patterns': ['hi', 'how are you', 'is anyone there', 'hello', 'whats up', 'hey', 'yo', 'listen', 'please help me', 'i am learner from', 'i belong to', 'aiml batch', 'aifl batch', 'i am from', 'my pm is', 'blended', 'online', 'i am from', 'hey ya', 'talking to you for first time', 'hey there', 'i need help'], 'responses': ['Hello! how can i help you ?'], 'context_set': ''}, {'tag': 'Exit', 'patterns': ['thank you', 'thanks', 'cya', 'see you', 'later', 'see you later', 'goodbye', 'i am leaving', 'have a Good day', 'you helped me', 'thanks a lot', 'thanks a ton', 'you are the best', 'great help', 'too good', 'you are a good learning buddy'], 'responses': ['I hope I was able to assist you, Good Bye'], 'context_set': ''}, {'tag': 'Olympus', 'patterns': ['olympus', ' i have login issue with olympus', 'explain me how olympus works', 'I am not able to understand olympus', 'olympus window not working', 'no access to olympus', 'unable to see link in olympus', 'no link visible on olympus', 'whom to contact for olympus', 'lot of problem with olympus', 'olypus is not a good tool', 'lot of problems with olympus', 'how to use olympus', 'teach me olympus'], 'responses': ['Link: Olympus wiki'], 'context_set': ''}, {'tag': 'SL', 'patterns': ['i am not able to understand svm', 'explain me how machine learning works', 'i am not able to understand naive bayes', 'i am not able to understand logistic regression', 'i am not able to understand ensemble techb=niques', 'i am not able to understand knn', 'i am not able to understand knn imputer', 'i am not able to understand cross validation', 'i am not able to understand boosting', 'i am not able to understand random forest', 'i am not able to understand ada boosting', 'i am not able to understand gradient boosting', 'machine learning', 'ML', 'SL', 'what is supervised learning', 'supervised learning', 'knn', 'logistic regression', 'regression', 'classification', 'naive bayes', 'nb', 'ensemble techniques', 'what is bagging', 'bagging', 'boosting', 'ada boosting', 'ada', 'gradient boosting', 'hyper parameters'], 'responses': ['Link: Machine Learning wiki '], 'context_set': ''}, {'tag': 'NN', 'patterns': ['what is deep learning', 'unable to understand deep learning', 'explain me how deep learning works', 'i am not able to understand deep learning', 'not able to understand neural nets', 'very diffult to understand neural nets', 'unable to understand neural nets', 'ann', 'artificial intelligence', 'artificial neural networks', 'weights', 'how does activation fuction works', 'activation function', 'hidden layers', 'softmax', 'sigmoid', 'relu', 'otimizer', 'forward propagation', 'backward propagation', 'epochs', 'epoch', 'what is an epoch', 'adam', 'expansion of sgd', 'sgd'], 'responses': ['Link: Neural Nets wiki'], 'context_set': ''}, {'tag': 'Bot', 'patterns': ['what is your name', 'who are you', 'name please', 'when are your hours of opertions', 'what are your working hours', 'hours of operation', 'working hours', 'hours'], 'responses': ['I am your virtual learning assistant'], 'context_set': ''}, {'tag': 'Profane', 'patterns': ['what the hell', 'bloody stupid bot', 'do you think you are very smart', 'screw you', 'i hate you', 'you are stupid', 'jerk', 'you are a joke', 'useless piece of shit'], 'responses': ['Please use respectful words'], 'context_set': ''}, {'tag': 'Ticket', 'patterns': ['my problem is not solved', 'you did not help me', 'not a good solution', 'bad solution', 'not good solution', 'no help', 'wasted my time', 'useless bot', 'create a ticket'], 'responses': ['Tarnsferring the request to your PM'], 'context_set': ''}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Bo0HoiJwYlY"
      },
      "source": [
        "Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZNBYwfzNly5"
      },
      "source": [
        "token = [] ## total words in the corpus\n",
        "labels = [] ## target\n",
        "tokenised_word = []\n",
        "total_tags = []\n",
        "\n",
        "for intent in corpus['intents']:\n",
        "  for pattern in intent['patterns']:\n",
        "    temp = nltk.word_tokenize(pattern)\n",
        "    token.extend(temp)\n",
        "    tokenised_word.append(temp)\n",
        "    total_tags.append(intent['tag'])\n",
        "\n",
        "  if intent['tag'] not in labels:\n",
        "    labels.append(intent['tag'])"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_boXzdYNl1f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bceafd4e-11f8-4296-96de-963c8b2bf44b"
      },
      "source": [
        "len(token)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfA4xZEaNl4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff8fac8b-c68f-4868-e5fb-cb7282efd4d1"
      },
      "source": [
        "len(tokenised_word)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoCfeiPjNmBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10dc964-99a6-4f14-c4dd-a4977e5e3733"
      },
      "source": [
        "print(labels)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Intro', 'Exit', 'Olympus', 'SL', 'NN', 'Bot', 'Profane', 'Ticket']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z05r6eaqNmEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11cca37-31ce-48ab-e5f1-062083ce6ec6"
      },
      "source": [
        "print(total_tags)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Intro', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Exit', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'Olympus', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'SL', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'NN', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Bot', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Profane', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket', 'Ticket']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ_S3zMAfH_d"
      },
      "source": [
        "** Applying the lemmetiser**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai88XRnWy1af",
        "outputId": "b6442192-da3d-41f7-b6dd-92af787fe39e"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeQ9MY3HygB3"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_oWkiWbNmHF"
      },
      "source": [
        "Train = []\n",
        "Target = []\n",
        "\n",
        "out_empty = [0 for _ in range(len(labels))]\n",
        "\n",
        "for i,doc in enumerate(tokenised_word):\n",
        "  bag = []\n",
        "\n",
        "  w_stem = [lemmatizer.lemmatize(w.lower()) for w in doc] \n",
        "\n",
        "#Creating bag of words\n",
        "  for w in token:\n",
        "     if w in w_stem:\n",
        "       bag.append(1)\n",
        "     else:\n",
        "       bag.append(0)\n",
        "\n",
        "  output_row = out_empty[:]\n",
        "  output_row[labels.index(total_tags[i])] = 1\n",
        "\n",
        "  Train.append(bag) #List\n",
        "  Target.append(output_row) #List"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9ewMQgsjiAx"
      },
      "source": [
        "## Building Text Classification NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI5gcsiU20Yp"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byPn7NnDjq0U"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten())\n",
        "model.add(Dense(130,activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(65,activation = 'relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(8,activation = 'softmax'))"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3mg3GqRjq2u"
      },
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StDux3uj1T-2"
      },
      "source": [
        "checkpoint= ModelCheckpoint('/content/chatbot.h5',save_best_only=True, monitor='accuracy', \n",
        "                                                    mode='max', verbose=1)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLc00fCJjq5X",
        "outputId": "fa4c3b8a-9306-44e4-fce8-a4d9dcb6bced"
      },
      "source": [
        "model.fit(np.array(Train), np.array(Target), epochs=20, batch_size=15,callbacks=[checkpoint],verbose=1)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "9/9 [==============================] - 1s 4ms/step - loss: 2.7009 - accuracy: 0.1535\n",
            "\n",
            "Epoch 00001: accuracy improved from -inf to 0.17778, saving model to /content/chatbot.h5\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 1.7404 - accuracy: 0.3957\n",
            "\n",
            "Epoch 00002: accuracy improved from 0.17778 to 0.42222, saving model to /content/chatbot.h5\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 0s 4ms/step - loss: 1.2780 - accuracy: 0.5894\n",
            "\n",
            "Epoch 00003: accuracy improved from 0.42222 to 0.57778, saving model to /content/chatbot.h5\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.9693 - accuracy: 0.6915\n",
            "\n",
            "Epoch 00004: accuracy improved from 0.57778 to 0.68148, saving model to /content/chatbot.h5\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.7569 - accuracy: 0.7813\n",
            "\n",
            "Epoch 00005: accuracy improved from 0.68148 to 0.77037, saving model to /content/chatbot.h5\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.8714\n",
            "\n",
            "Epoch 00006: accuracy improved from 0.77037 to 0.87407, saving model to /content/chatbot.h5\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.5764 - accuracy: 0.8370\n",
            "\n",
            "Epoch 00007: accuracy did not improve from 0.87407\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.8681\n",
            "\n",
            "Epoch 00008: accuracy did not improve from 0.87407\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.8263\n",
            "\n",
            "Epoch 00009: accuracy did not improve from 0.87407\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3877 - accuracy: 0.9256\n",
            "\n",
            "Epoch 00010: accuracy improved from 0.87407 to 0.90370, saving model to /content/chatbot.h5\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.9318\n",
            "\n",
            "Epoch 00011: accuracy improved from 0.90370 to 0.92593, saving model to /content/chatbot.h5\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.9314\n",
            "\n",
            "Epoch 00012: accuracy improved from 0.92593 to 0.94074, saving model to /content/chatbot.h5\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2229 - accuracy: 0.9749\n",
            "\n",
            "Epoch 00013: accuracy improved from 0.94074 to 0.96296, saving model to /content/chatbot.h5\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9680\n",
            "\n",
            "Epoch 00014: accuracy did not improve from 0.96296\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2223 - accuracy: 0.9642\n",
            "\n",
            "Epoch 00015: accuracy did not improve from 0.96296\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.2391 - accuracy: 0.9465\n",
            "\n",
            "Epoch 00016: accuracy did not improve from 0.96296\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9668\n",
            "\n",
            "Epoch 00017: accuracy did not improve from 0.96296\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1551 - accuracy: 0.9678\n",
            "\n",
            "Epoch 00018: accuracy improved from 0.96296 to 0.97037, saving model to /content/chatbot.h5\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1629 - accuracy: 0.9771\n",
            "\n",
            "Epoch 00019: accuracy improved from 0.97037 to 0.98519, saving model to /content/chatbot.h5\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 0s 3ms/step - loss: 0.1291 - accuracy: 0.9807\n",
            "\n",
            "Epoch 00020: accuracy did not improve from 0.98519\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f67a7e20f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTYjJyY9yR7J"
      },
      "source": [
        "def tokenise_sentence(inp):\n",
        "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
        "    temp = w_tokenizer.tokenize(inp)\n",
        "    return temp"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqVz5Vug0OLG"
      },
      "source": [
        "def bag_of_words(inp,token):\n",
        "  w_tem = tokenise_sentence(inp)\n",
        "  word = []\n",
        "  bags = []\n",
        "  w_stem = [lemmatizer.lemmatize(wor.lower()) for wor in w_tem] \n",
        "#Creating bag of words\n",
        "  for w in token:\n",
        "    if w in w_stem:\n",
        "      bags.append(1)\n",
        "    else:\n",
        "      bags.append(0)\n",
        "  word.append(bags)\n",
        "  return(np.array(word))"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONYzlSaMlXem"
      },
      "source": [
        "def chat():\n",
        "  print(\"chat with jason(type: quit to stop\")\n",
        "  print(\"If answer is not right (type:*)\")\n",
        "  while True:\n",
        "    inp = input(\"\\n\\nYou: \")\n",
        "    if inp.lower()==\"*\":\n",
        "      print(\"Jason: Please rephrase your question and try again\")\n",
        "    if inp.lower()==\"quit\":\n",
        "      print(\"Thank you! Bye\")\n",
        "      break\n",
        "   \n",
        "    result = model.predict(bag_of_words(inp,token))\n",
        "    result_index = np.argmax(result)\n",
        "    tag = labels[result_index]\n",
        "\n",
        "    for tg in corpus[\"intents\"]:\n",
        "      if tg['tag'] == tag:\n",
        "        responses = tg['responses']\n",
        "        \n",
        "    print(random.choice(responses))"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNsJszrp3pvq",
        "outputId": "e794247a-bc8a-43e8-fc41-af8609b34b0e"
      },
      "source": [
        "chat()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chat with jason(type: quit to stop\n",
            "If answer is not right (type:*)\n",
            "\n",
            "\n",
            "You: hello\n",
            "Hello! how can i help you ?\n",
            "\n",
            "\n",
            "You: have olympus login issue\n",
            "Link: Olympus wiki\n",
            "\n",
            "\n",
            "You: i hate you\n",
            "Please use respectful words\n",
            "\n",
            "\n",
            "You: not a good solution\n",
            "Tarnsferring the request to your PM\n",
            "\n",
            "\n",
            "You: what is your name\n",
            "I am your virtual learning assistant\n",
            "\n",
            "\n",
            "You: how logistic regression works\n",
            "Link: Machine Learning wiki \n",
            "\n",
            "\n",
            "You: explain ensemble techniques\n",
            "Link: Machine Learning wiki \n",
            "\n",
            "\n",
            "You: hyperparameter tunning\n",
            "Link: Machine Learning wiki \n",
            "\n",
            "\n",
            "You: how to set hidden layers\n",
            "Hello! how can i help you ?\n",
            "\n",
            "\n",
            "You: hidden layers\n",
            "Link: Neural Nets wiki\n",
            "\n",
            "\n",
            "You: how gradient boosting works\n",
            "Link: Machine Learning wiki \n",
            "\n",
            "\n",
            "You: how to operate olympus\n",
            "Link: Olympus wiki\n",
            "\n",
            "\n",
            "You: softmax layers\n",
            "Link: Neural Nets wiki\n",
            "\n",
            "\n",
            "You: you are stupid\n",
            "Please use respectful words\n",
            "\n",
            "\n",
            "You: complete jerk\n",
            "Link: Machine Learning wiki \n",
            "\n",
            "\n",
            "You: thank you\n",
            "I hope I was able to assist you, Good Bye\n",
            "\n",
            "\n",
            "You: quit\n",
            "Thank you! Bye\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77SQ6qejaH73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14547263-027b-41b1-8dd0-78511454f1fb"
      },
      "source": [
        "!jupyter nbconvert --to html AIML_R8_Project1_Word_Embeddings_with_DNN_&_Chatbot.ipynb"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: _Chatbot.ipynb: command not found\n",
            "[NbConvertApp] WARNING | pattern u'AIML_R8_Project1_Word_Embeddings_with_DNN_' matched no files\n",
            "This application is used to convert notebook files (*.ipynb) to various other\n",
            "formats.\n",
            "\n",
            "WARNING: THE COMMANDLINE INTERFACE MAY CHANGE IN FUTURE RELEASES.\n",
            "\n",
            "Options\n",
            "-------\n",
            "\n",
            "Arguments that take values are actually convenience aliases to full\n",
            "Configurables, whose aliases are listed on the help line. For more information\n",
            "on full configurables, see '--help-all'.\n",
            "\n",
            "--execute\n",
            "    Execute the notebook prior to export.\n",
            "--allow-errors\n",
            "    Continue notebook execution even if one of the cells throws an error and include the error message in the cell output (the default behaviour is to abort conversion). This flag is only relevant if '--execute' was specified, too.\n",
            "--no-input\n",
            "    Exclude input cells and output prompts from converted document. \n",
            "    This mode is ideal for generating code-free reports.\n",
            "--stdout\n",
            "    Write notebook output to stdout instead of files.\n",
            "--stdin\n",
            "    read a single notebook file from stdin. Write the resulting notebook with default basename 'notebook.*'\n",
            "--inplace\n",
            "    Run nbconvert in place, overwriting the existing notebook (only \n",
            "    relevant when converting to notebook format)\n",
            "-y\n",
            "    Answer yes to any questions instead of prompting.\n",
            "--clear-output\n",
            "    Clear output of current file and save in place, \n",
            "    overwriting the existing notebook.\n",
            "--debug\n",
            "    set log level to logging.DEBUG (maximize logging output)\n",
            "--no-prompt\n",
            "    Exclude input and output prompts from converted document.\n",
            "--generate-config\n",
            "    generate default config file\n",
            "--nbformat=<Enum> (NotebookExporter.nbformat_version)\n",
            "    Default: 4\n",
            "    Choices: [1, 2, 3, 4]\n",
            "    The nbformat version to write. Use this to downgrade notebooks.\n",
            "--output-dir=<Unicode> (FilesWriter.build_directory)\n",
            "    Default: ''\n",
            "    Directory to write output(s) to. Defaults to output to the directory of each\n",
            "    notebook. To recover previous default behaviour (outputting to the current\n",
            "    working directory) use . as the flag value.\n",
            "--writer=<DottedObjectName> (NbConvertApp.writer_class)\n",
            "    Default: 'FilesWriter'\n",
            "    Writer class used to write the  results of the conversion\n",
            "--log-level=<Enum> (Application.log_level)\n",
            "    Default: 30\n",
            "    Choices: (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL')\n",
            "    Set the log level by value or name.\n",
            "--reveal-prefix=<Unicode> (SlidesExporter.reveal_url_prefix)\n",
            "    Default: u''\n",
            "    The URL prefix for reveal.js (version 3.x). This defaults to the reveal CDN,\n",
            "    but can be any url pointing to a copy  of reveal.js.\n",
            "    For speaker notes to work, this must be a relative path to a local  copy of\n",
            "    reveal.js: e.g., \"reveal.js\".\n",
            "    If a relative path is given, it must be a subdirectory of the current\n",
            "    directory (from which the server is run).\n",
            "    See the usage documentation\n",
            "    (https://nbconvert.readthedocs.io/en/latest/usage.html#reveal-js-html-\n",
            "    slideshow) for more details.\n",
            "--to=<Unicode> (NbConvertApp.export_format)\n",
            "    Default: 'html'\n",
            "    The export format to be used, either one of the built-in formats\n",
            "    ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf',\n",
            "    'python', 'rst', 'script', 'slides'] or a dotted object name that represents\n",
            "    the import path for an `Exporter` class\n",
            "--template=<Unicode> (TemplateExporter.template_file)\n",
            "    Default: u''\n",
            "    Name of the template file to use\n",
            "--output=<Unicode> (NbConvertApp.output_base)\n",
            "    Default: ''\n",
            "    overwrite base name use for output files. can only be used when converting\n",
            "    one notebook at a time.\n",
            "--post=<DottedOrNone> (NbConvertApp.postprocessor_class)\n",
            "    Default: u''\n",
            "    PostProcessor class used to write the results of the conversion\n",
            "--config=<Unicode> (JupyterApp.config_file)\n",
            "    Default: u''\n",
            "    Full path of a config file.\n",
            "\n",
            "To see all available configurables, use `--help-all`\n",
            "\n",
            "Examples\n",
            "--------\n",
            "\n",
            "    The simplest way to use nbconvert is\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb\n",
            "    \n",
            "    which will convert mynotebook.ipynb to the default format (probably HTML).\n",
            "    \n",
            "    You can specify the export format with `--to`.\n",
            "    Options include ['asciidoc', 'custom', 'html', 'latex', 'markdown', 'notebook', 'pdf', 'python', 'rst', 'script', 'slides'].\n",
            "    \n",
            "    > jupyter nbconvert --to latex mynotebook.ipynb\n",
            "    \n",
            "    Both HTML and LaTeX support multiple output templates. LaTeX includes\n",
            "    'base', 'article' and 'report'.  HTML includes 'basic' and 'full'. You\n",
            "    can specify the flavor of the format used.\n",
            "    \n",
            "    > jupyter nbconvert --to html --template basic mynotebook.ipynb\n",
            "    \n",
            "    You can also pipe the output to stdout, rather than a file\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --stdout\n",
            "    \n",
            "    PDF is generated via latex\n",
            "    \n",
            "    > jupyter nbconvert mynotebook.ipynb --to pdf\n",
            "    \n",
            "    You can get (and serve) a Reveal.js-powered slideshow\n",
            "    \n",
            "    > jupyter nbconvert myslides.ipynb --to slides --post serve\n",
            "    \n",
            "    Multiple notebooks can be given at the command line in a couple of \n",
            "    different ways:\n",
            "    \n",
            "    > jupyter nbconvert notebook*.ipynb\n",
            "    > jupyter nbconvert notebook1.ipynb notebook2.ipynb\n",
            "    \n",
            "    or you can specify the notebooks list in a config file, containing::\n",
            "    \n",
            "        c.NbConvertApp.notebooks = [\"my_notebook.ipynb\"]\n",
            "    \n",
            "    > jupyter nbconvert --config mycfg.py\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EADcEPDFaH-l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}