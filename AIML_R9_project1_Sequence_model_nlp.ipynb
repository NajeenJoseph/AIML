{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIML_R9_project1_Sequence_model_nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbhTMEE_tvgk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e025cd5-963e-4003-e785-85be5460cb03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdoMuxo13Xps"
      },
      "source": [
        "#Objective:\n",
        "\n",
        "   Tobuild sequential NLP classifier to determine the customer sentiments based on the review comments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JV4Yeqtp3YCu"
      },
      "source": [
        "## About Dataset:\n",
        "   \n",
        "   *) Using IMDB movie review dataset has 50000 movie reviews with balanced sample of positive/negative reviews.\n",
        "\n",
        "   *) The reviews are already preprocessed and encoded with word index(integers) by the frequency of each words. Hence text preprocessing is not required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "537sR9rd3YQG"
      },
      "source": [
        "#Steps:\n",
        "\n",
        "*) Loading the dataset and preparing Train & Test data.\n",
        "\n",
        "*) Since the reviews had already been preprocessed and indexed the data is good to go with tokenisation and vectorization.\n",
        "\n",
        "*) Padding the sequence to make all the reviews of same length with 250 characters.\n",
        "\n",
        "*) Decoding the original features.\n",
        "\n",
        "*) Model Building using Embedding layer along with Pre trained glove model.\n",
        "\n",
        "*) LSTM layer and Dense layer as output layer with sigmoid activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbkwycWuTvW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import imdb"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7WpBcebTekD"
      },
      "source": [
        "##Loading Dataset & Preparing Train and Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c5kppIFuTzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12887ef3-430c-4b85-bdc3-fcef8e6caa10"
      },
      "source": [
        "(x_train,y_train),(x_test, y_test) = imdb.load_data(num_words=10000) ##using the top 10000 frequent words and elimination the top 15 most frequent words."
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_A3dZaYQf8m",
        "outputId": "2deae9a7-a819-4e19-f49d-c14f0594df02"
      },
      "source": [
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,) (25000,) (25000,) (25000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsUqk_38GkaL",
        "outputId": "50bcfefa-9e5b-489a-9660-8b12acbfb38d"
      },
      "source": [
        "np.unique(x_train)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([1, 2, 2, 2, 2, 9, 4, 86, 6594, 20, 7, 1300, 2, 6457, 5, 1238, 9, 24, 44, 2, 2, 2, 42, 2, 12, 9, 1004, 6, 55, 338, 1830, 11, 6, 2, 11, 6327, 121, 4, 2, 26, 3276, 2, 2, 2, 5233, 372, 4780, 13, 81, 24, 124, 4, 282, 138, 6457, 6546, 14, 1579, 756, 5, 2776, 8, 276, 2511, 21, 849, 36, 26, 55, 619, 537, 49, 7, 98, 483, 2244, 13, 1276, 40, 4, 1301, 65, 7, 4, 430, 5, 27, 336, 15, 925, 19, 6, 313, 7, 68, 205, 5, 2171, 34, 98, 4, 65, 7, 4, 3000, 430, 15, 2251, 29, 7446, 6, 1374, 4, 65, 7, 4, 132, 15, 5245, 677, 476, 17, 48, 36, 71, 68, 205, 3197, 5, 2847, 5, 4, 65, 7, 4, 185, 255, 5233, 34, 41, 2, 61, 2302, 9, 3020, 10, 10, 425, 3829, 2, 475, 1604, 2, 5438, 2, 2, 475, 4, 96, 7, 4, 113]),\n",
              "       list([1, 2, 2, 2, 2, 9, 6, 87, 20, 24, 64, 11, 4, 291, 12, 16, 324, 21, 82, 150, 45, 35, 498, 20, 63, 9, 24, 5903, 60, 11, 6161, 1117, 4, 167, 2, 6, 52, 1321, 2703, 5, 1346, 93, 4, 65, 38, 3557, 10, 10, 4, 20, 1791, 72, 7, 4, 303, 785, 162, 2869, 20, 2, 2, 5203, 2, 2, 63, 9, 7, 4, 729, 2989]),\n",
              "       list([1, 2, 2, 2, 2, 9, 6, 120, 5533, 6454, 2220, 252, 94, 6, 31, 7, 4, 91, 3005, 108, 21, 54, 12, 266, 8, 1500, 60, 4, 5075, 80, 7970, 14, 31, 138, 4, 108, 229, 9, 17, 2374, 17, 6, 241, 291, 154, 896, 229, 9, 711, 209, 6, 52, 229, 60, 4, 833, 167, 7, 32, 58, 566, 81, 233, 7931, 9, 1055, 34, 4, 91, 1112, 365, 2, 2, 5883, 2, 5, 8110, 381, 3256, 11, 12, 21, 164, 23, 703, 70, 607, 25, 48, 25, 229, 9, 1904, 3366, 180, 10, 10, 354, 6301, 4029, 9, 6, 2496, 284, 21, 89, 100, 29, 864, 6, 217, 40, 14, 4406, 5415, 9, 87, 284, 11, 192, 240, 4, 3719, 1907, 1698, 8391, 4029, 47, 115, 610, 38, 893, 59, 272, 1380, 5, 889, 25, 32, 759, 56, 9867, 8344, 4698, 152, 79, 27, 688, 11, 133, 2, 2, 2, 2, 5, 2, 2, 26, 1053, 10, 10, 2, 9, 6, 357, 22, 4, 108, 2104, 33, 4, 953, 1052, 144, 25, 401, 245]),\n",
              "       ...,\n",
              "       list([1, 9955, 9, 6, 906, 3198, 11, 4, 7627, 201, 7, 2, 2473, 1184, 1955, 2, 4, 108, 71, 3711, 33, 2, 5, 71, 526, 1125, 5, 6885, 34, 49, 7, 4, 350, 676, 39, 2991, 5638, 758, 2, 2, 587, 2, 2, 3447, 1532, 5, 4124, 2, 4, 2, 3774, 2, 2, 4, 544, 18, 2, 5, 4, 537, 5, 2, 2559, 18, 111, 7, 4, 108, 16, 2, 34, 2, 2, 13, 963, 884, 9295, 4, 326, 16, 8, 2833, 1121, 5867, 19, 486, 5, 3983, 2656, 772, 4, 109, 7, 2, 17, 6, 404, 1566, 463, 29, 16, 4, 2, 4, 117, 2, 37, 62, 81, 285, 335, 24, 424, 8, 81, 1793, 8, 3447, 1532, 4, 3167, 69, 8, 30, 2, 34, 2, 8699, 21, 1272, 2, 82, 2, 4, 9053, 35, 1732, 1166, 7, 2204, 3828, 1101, 5, 2, 640, 434, 53, 74, 2253, 8023, 7, 4, 58, 62, 1741, 32, 18, 4, 2798, 52, 7, 265, 10, 10, 17, 4, 425, 62, 7147, 14, 1072, 9, 35, 2, 7, 4, 2, 671, 7, 9955, 4, 956, 9, 35, 1272, 1250, 1955, 2, 4474, 375, 8, 160, 1631, 11, 4, 2, 142, 25, 528, 67, 11, 101, 85, 363, 108, 7, 4, 999, 5, 68, 5717, 2599, 517, 4, 1871, 2660, 75, 7679, 17, 35, 2, 7759, 44, 6, 9153, 9, 2, 95, 3694, 95, 679, 83, 35, 3437, 2532, 2, 15, 2, 4, 1250, 4, 2656, 9, 849, 3983, 4, 1224, 7, 31, 7067, 1631, 9, 2399, 17, 6, 2, 4360, 137, 4, 2, 2491, 7, 160, 9, 5760, 17, 9147, 893, 945, 13, 963, 9179, 7926, 6, 1631, 3234, 27, 1642, 125, 5556, 405, 5, 159, 25, 124, 12, 779, 2, 9, 1549, 11, 175, 458, 2, 2, 33, 15, 2, 1340, 376, 257, 85, 15, 4, 4201, 3026, 47, 77, 2, 2, 1111, 6877, 46, 2543, 4750, 28, 5955, 23, 4, 428, 313, 8815, 5, 4, 860, 26, 11, 2642, 4, 2057, 413, 126, 53, 2427, 5, 7498, 366, 33, 236, 4, 1250, 9, 2, 18, 2, 2, 5, 1955, 2, 47, 77, 2897, 56, 11, 6, 8425, 2768, 10, 10, 14, 9, 6, 545, 1134, 418, 7, 157, 4, 1057, 2, 68, 756, 19, 2210, 5, 6078, 1708, 5, 4, 749, 9, 131, 6, 7513, 31, 11, 1136, 153, 2002, 110, 15, 2, 687, 147, 42, 3792, 70, 5287, 32, 2572, 7, 1358, 9955, 15, 4600, 53, 6143, 74, 126, 1216, 8, 7293, 8424, 88, 4, 2131, 47, 3827, 4, 1955, 2, 7, 263, 58, 26, 502, 8, 3851, 68, 205, 9179, 7926, 2864, 963, 4738, 2, 5, 2, 7124, 9955, 9, 6, 1281, 463, 7, 6, 7627, 4965, 22, 625, 2963, 749, 152, 235, 33, 32, 1967, 11, 192, 12, 203, 30, 53, 2, 74, 126]),\n",
              "       list([1, 9982, 188, 8636, 8, 990, 5, 15, 1687, 1368, 3590, 10, 10, 11, 2571, 6, 604, 6, 1340, 1974, 15, 4, 325, 9, 120, 5, 26, 5576, 145, 344, 54, 36, 1466, 6, 762, 7, 2, 587, 1368, 3590, 1045, 6, 1168, 2431, 342, 2, 548, 5, 6, 346, 3298, 303, 3590, 5, 49, 2, 232, 3259, 6, 2863, 988, 2428, 142, 42, 85, 10, 10, 605, 8, 4, 984, 6047, 5, 2, 232, 9, 971, 6, 2634, 429, 5522, 2, 240, 1112, 33, 86, 21, 103, 5522, 2, 5589, 8, 4266, 1588, 19, 6, 5215, 240, 918, 8, 8402, 5, 9, 324, 11, 4, 419, 23, 412, 699, 14, 9, 617, 11, 368, 2207, 1589, 17, 6, 1636, 3174, 23, 298, 9572, 63, 832, 3590, 8, 2, 4, 154, 5408, 60, 151, 29, 286, 165, 173, 7, 15, 5408, 8, 895, 19, 11, 661, 8, 2, 2, 5, 1056, 180, 3086, 7, 84, 10, 10, 2, 9, 6, 2, 379, 22, 21, 18, 32, 15, 45, 82, 6, 52, 462, 5, 206, 3015, 99, 14, 9, 31, 7, 148, 102, 121, 2091, 9, 348, 6, 1876, 2, 89, 334, 100, 3590, 1258, 6, 4025, 1811, 11, 4, 419, 39, 160, 1707, 209, 2073, 39, 2, 42, 60, 2244, 6, 2054, 82, 12, 186, 15, 134, 493, 70, 1056, 180, 4634, 7, 1392, 8452, 11, 162, 782, 209, 4, 568, 8981, 10, 10, 225, 958, 7, 503, 20, 3001, 8, 7668, 23, 133, 39, 488, 2, 9589, 116, 11, 4, 2571, 720, 8, 4, 3818, 21, 1097, 1149, 341, 7, 31, 7, 4, 1737, 8, 4, 499, 9270, 5127, 200, 3590, 5, 5522, 2, 5, 903, 24, 859, 4, 2, 2491, 34, 4, 799, 7, 4, 4194, 2121, 112, 296, 23, 699, 11, 938, 754, 839, 6, 2115, 3325, 8, 61, 2, 744, 15, 227, 10, 10, 45, 46, 50, 18, 6, 2, 818, 12, 48, 25, 28, 6, 281, 7, 1285, 67, 89, 111, 211, 25, 70, 1466, 4, 370, 1051, 99]),\n",
              "       list([1, 9995, 2, 7, 2208, 7335, 3135, 4173, 3783, 509, 1683, 4702, 2, 2, 6, 201, 7, 6415, 687, 2, 2, 7, 6387, 548, 139, 7583, 295, 34, 4485, 5302, 2, 2, 2, 7, 2, 2, 146, 24, 1017, 2282, 133, 21, 4, 1591, 3113, 786, 2, 16, 125, 4, 2, 9790, 2039, 137, 267, 2, 5, 2, 120, 2024, 980, 2, 1248, 5666, 727, 1405, 6879, 1060, 6442, 18, 2, 1461, 2, 1883, 445, 109, 5369, 3696, 33, 236, 786, 5580, 7994, 8, 2, 2, 103, 2, 98, 11, 2, 1461, 24, 66, 351, 1461, 165, 116, 17, 2545, 18, 6717, 8694, 5514, 980, 2545, 165, 734, 18, 2311, 52, 84, 157, 18, 7232, 11, 661, 8, 607, 3531, 223, 1066, 445, 9236, 996, 8, 2898, 4931, 8, 5526, 8316, 7880, 154, 378, 459, 18, 6942, 632, 5, 79, 2024, 18, 68, 4918, 813, 2456, 2, 17, 840, 4807, 3854, 23, 136, 159, 5770, 852, 1698, 632, 7708, 7993, 1003, 1372, 5747, 2, 7, 5840, 5408, 11, 7200, 120, 4682, 7, 2, 3368, 2103, 8, 1140, 2, 880, 1692, 7, 68, 205, 3565, 5903, 21, 3204, 1372, 2, 2, 1098, 125, 128, 2429, 21, 9000, 2, 632, 2, 245, 39, 3526, 5, 9386, 2690, 6, 4951, 7, 2, 496, 90, 103, 316, 47, 348, 56, 2, 483, 2, 2865, 56, 6, 9739, 445, 9236, 2568, 2464, 8, 632, 29, 57, 1207, 1085, 17, 6, 3842, 632, 3055, 8, 516, 5765, 2, 88, 240, 128, 74, 15, 7906, 700, 2143, 109, 166, 642, 2, 5, 6358, 795, 7771, 6474, 2, 11, 1526, 4041, 2, 2, 2, 2, 2, 31, 160, 143, 6, 201, 7, 3404, 5, 85, 1748, 2, 15, 62, 516, 6, 2691, 6945, 132, 2, 4193, 7, 1056, 6756, 4262, 19, 164, 21, 2, 2, 1141, 281, 5, 4, 4461, 7, 5681, 2, 5, 1175, 2, 2628, 7232, 772, 447, 2066, 588, 17, 8508, 18, 5580, 2, 10, 10, 13, 100, 140, 23, 21, 14, 9, 43, 2, 48, 335, 120, 4, 559, 7, 3917, 5, 24, 581, 11, 9484, 3231, 225, 242, 164, 133, 18, 25, 2, 195, 45, 24, 99, 230, 125, 7, 2291, 18, 3783, 102, 38, 2, 32, 207, 398, 48, 25, 191, 79, 195, 7, 4, 512])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJq7ELGFJZ8d",
        "outputId": "16520661-ea6e-40c5-e433-1c3704ec2154"
      },
      "source": [
        "max(max(x_train))"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9995"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww09x94fuT4L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9790dda-c032-4185-b36a-39c786c292de"
      },
      "source": [
        "print(x_train[88])"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 18, 6, 20, 19, 6, 114, 40, 14, 13, 62, 1760, 7625, 2, 11, 4, 86, 747, 234, 5, 471, 12, 125, 21, 14, 16, 55, 73, 93, 19, 921, 9271, 87, 116, 5, 49, 2070, 163, 388, 12, 16, 82, 221, 8, 67, 6, 275, 1181, 6, 2, 31, 33, 15, 61, 322, 5, 13, 199, 2, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vljRzmIRRAg4",
        "outputId": "23cb78c0-8a6c-4f9e-d16a-a58a25e45403"
      },
      "source": [
        "print(y_train[88])"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ITkcVAfuT6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f4c861-c447-40e8-c977-e6e6e8ee3d47"
      },
      "source": [
        "print(x_test[235])"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1760, 13, 244, 6, 801, 948, 2, 250, 21, 103, 149, 14, 22, 23, 6221, 7, 265, 146, 260, 275, 8353, 5, 82, 13, 122, 24, 124, 15, 61, 514, 748, 1182, 2, 93, 160, 22, 198, 44, 1830, 7, 9415, 625, 543, 4056, 344, 9, 5907, 34, 1714, 2, 2, 5, 6920, 2, 9374, 525, 5, 89, 6, 2, 185, 2, 773, 3220, 4, 251, 5, 2939, 4, 483, 7, 9180, 4, 2, 13, 119, 4, 1334, 1563, 9180, 25, 124, 103, 149, 4, 22, 4, 3096, 1578, 72, 7, 4, 49, 7, 4, 3096, 39, 1561, 5, 46, 7, 4, 690, 11, 4, 22, 13, 119, 1106, 6, 378, 11, 4, 1662, 54, 13, 1941, 15, 613, 12, 220, 93, 72, 1415, 10, 10, 14, 389, 22, 16, 4, 333, 5, 477, 792, 8, 216, 46, 7, 4, 2, 1182, 4, 22, 16, 1822, 170, 8, 30, 626, 23, 9561, 7, 9549, 21, 237, 4, 2, 3008, 910, 626, 2, 2485, 908, 5510, 1194, 4, 1304, 8, 8290, 7, 4, 172, 291, 21, 443, 5698, 472, 435, 83, 6, 95, 2, 3627, 7, 394, 2852, 260, 4, 6343, 7, 636, 107, 504, 103, 4, 1274, 23, 4658, 8691, 443, 5698, 16, 6, 4118, 1690, 5, 1638, 8, 4, 7, 2431, 5, 3833, 2, 39, 4, 1182, 36, 69, 2921, 11, 2, 5, 2, 4, 1169, 17, 804, 2830, 160, 666, 2367, 11, 68, 5925, 16, 4, 192, 15, 2431, 5, 3833, 2, 71, 57, 1207, 1386, 8, 31, 160, 688, 8, 2, 89, 619, 12, 16, 444, 13, 119, 199, 108, 39, 4, 2, 5638, 2, 5, 443, 5698]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT6xg7yDg0rq",
        "outputId": "1d955a42-0ef5-45d8-bbc3-9762e2c80cce"
      },
      "source": [
        "print(y_test[235])"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JV6cHTguT9m"
      },
      "source": [
        "##Pad Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2CTeCy9uUAH"
      },
      "source": [
        "max_length = 250 ## considering the first 250 words of each review"
      ],
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uTll6mtcjSm"
      },
      "source": [
        "####Tried with first 20,50, 70, 100,150,200 words in each review but the model gives lesser accuracy than 250. Hence considering first 250 words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pE5drf0uUC3"
      },
      "source": [
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen = max_length,padding = 'pre', truncating='post')"
      ],
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Erw-65pRSOcf"
      },
      "source": [
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,maxlen = max_length,padding = 'pre', truncating='post')"
      ],
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwermSFVSOsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc857ff-4da1-45b8-ac3b-83addb2926f9"
      },
      "source": [
        "X_train.shape ## Feature shape"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj26_VBOSOy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb0329f-6e8f-467a-a654-6c932bed4c98"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 250)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWxbbM8rbUfQ",
        "outputId": "4a51ed18-587b-4a9c-86aa-1a545ef1ae91"
      },
      "source": [
        "y_train.shape ##label shape"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrAABl9lSO1P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d9485e0-705d-4f7c-fc55-ec36e2c80cc1"
      },
      "source": [
        "print(X_train[95]) ## feature values"
      ],
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    1   13   66  215   28 1059    6  275\n",
            "   22   39    4  360    7    4    2   23   14 2138   88   33    6 2824\n",
            "    7    4   22  236  314    4  311   16   38    2   34    4    2   15\n",
            "  146   24   60 3988  320 2529   46  324   17   48    4 1723  197   29\n",
            "   71 6428   49 3922  162 3641   34 5267    6 4717  582    7  559   65\n",
            "    4   22    2  628 2219 1581 2057   19 7707 1581  116    4  354   11\n",
            "   14   22   26   38  753    5 1100   15   13 2626   31    7    4  156\n",
            "   16  170    8 1345   46   34   89 3658   36  468    8   30   34    4\n",
            "  229  803  433    9   15   45 6594   40   35  390    7 6127 4583   13\n",
            "   92  124   37   14  167 1291   29    9  279   29   47    2    7    4\n",
            " 2427   40    2    2  525   21    4  439    9   15   32    7    4    2\n",
            " 1046  907 2444    6  651    7    2 7557   15    9 5948 1892  133   13\n",
            "  100  391    4    2    7   14   22   44  747  153  596   21   54 2002\n",
            "  188 4890  141   17   78    2 1397 2391    5  123   72  119  138 1414\n",
            "   19   14 1360 6503   50    9  164  162    8   30  110  133]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7LK1uRUSO3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5685a250-37ab-4b28-99de-055196ce7623"
      },
      "source": [
        "print(y_train[95]) ## label"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JE3WULvThBaJ"
      },
      "source": [
        "## Decoding the fearture to get original sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOxarfAfhLWR"
      },
      "source": [
        "word_index = imdb.get_word_index() ## loading the word index from imdb"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WQ3FKGPhZUC"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()]) ## mapping the index to its respective words"
      ],
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBxepjjFhiIB"
      },
      "source": [
        "decoded_review1= ' '.join([reverse_word_index.get(i-3,'') for i in x_train[156]]) \n",
        "# indices are off by 3 because 0, 1, and 2 are reserverd indices for \"padding\", \"Start of sequence\" and \"unknown\""
      ],
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kmb-rbQRZtA"
      },
      "source": [
        "decoded_review = ' '.join([reverse_word_index.get(i-3,'') for i in X_train[156]]) "
      ],
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "8VKAXXOMjUi3",
        "outputId": "7dc8c467-1a4f-4090-b51c-3cb26eb968b8"
      },
      "source": [
        "decoded_review ## after padding first 250 words"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"                                                                                                      what i hate about this show is how poorly the leads are written these women have no self respect or dignity the entire plot is them throwing themselves at guys amanda  talent is completely wasted she was brilliant on all that and her own show why they would write her and jenny  as vapid  desperate men chasing old maid  is beyond me br br their plots and dialog remind me of the  homer says whenever his cartoon character  is not on screen everyone should ask where's  all the talk centers on whining about some guy and then whining to some guy sometimes they change it up and the guy  instead then they get back together or break up at the end the 2 women are either shallow stupid or sex  the only word i can think of is sucks\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "f38btU03h9rv",
        "outputId": "e7e022cb-0bdc-4a3b-e57e-c04c6ced2513"
      },
      "source": [
        "decoded_review1 ## original sentence"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" what i hate about this show is how poorly the leads are written these women have no self respect or dignity the entire plot is them throwing themselves at guys amanda  talent is completely wasted she was brilliant on all that and her own show why they would write her and jenny  as vapid  desperate men chasing old maid  is beyond me br br their plots and dialog remind me of the  homer says whenever his cartoon character  is not on screen everyone should ask where's  all the talk centers on whining about some guy and then whining to some guy sometimes they change it up and the guy  instead then they get back together or break up at the end the 2 women are either shallow stupid or sex  the only word i can think of is sucks\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D5NdGx8MCjP"
      },
      "source": [
        "## Building Model using Embedding layer(Word2Vec)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDItSffGjcHW"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding,LSTM, Dense,Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAxnktRFjcKb"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = Sequential()"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqROoBw7Vmqk"
      },
      "source": [
        "#### Adding Embedding layer\n",
        "    Embedding layer input = Batch_Size * Length of each review"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3badUbxcWQ7Z"
      },
      "source": [
        "vocab_size = 10000"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI1AfgbnjcNc"
      },
      "source": [
        "model.add(Embedding(vocab_size + 1,  # Vocabulary size and padding value\n",
        "                    50, #Embedding size\n",
        "                    input_length = max_length)) ## number of words in each review"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzvheElzjcP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc79561-f9f8-4074-cc4b-e11560d8d01a"
      },
      "source": [
        "model.output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 250, 50) dtype=float32 (created by layer 'embedding')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ccDTksVjcVI"
      },
      "source": [
        "model.add(Dropout(0.3))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dropout(0.3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jn4f9SNDXnu0"
      },
      "source": [
        "### Output layer using dense layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgaB1B97XbMy"
      },
      "source": [
        "model.add(Dense(1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI-TsZn3XzOs"
      },
      "source": [
        "model.compile(optimizer = 'adam',loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYQKqC1nYADb",
        "outputId": "bd3fa72a-ff4c-4c8f-b457-f35ed78ee51f"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 250, 50)           500050    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 250, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               91648     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 591,827\n",
            "Trainable params: 591,827\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpPSstD4YQdm"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSawnCL_YDHO",
        "outputId": "27f757a0-b3db-4689-8065-34a0e2cd4558"
      },
      "source": [
        "model.fit(X_train,y_train,batch_size = 64, epochs = 10, validation_data = (X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "391/391 [==============================] - 20s 30ms/step - loss: 0.5424 - accuracy: 0.7128 - val_loss: 0.4001 - val_accuracy: 0.8264\n",
            "Epoch 2/10\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.3240 - accuracy: 0.8701 - val_loss: 0.3495 - val_accuracy: 0.8560\n",
            "Epoch 3/10\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.2434 - accuracy: 0.9096 - val_loss: 0.3482 - val_accuracy: 0.8645\n",
            "Epoch 4/10\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.1993 - accuracy: 0.9296 - val_loss: 0.3636 - val_accuracy: 0.8482\n",
            "Epoch 5/10\n",
            "391/391 [==============================] - 11s 28ms/step - loss: 0.1642 - accuracy: 0.9423 - val_loss: 0.4157 - val_accuracy: 0.8408\n",
            "Epoch 6/10\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.1397 - accuracy: 0.9506 - val_loss: 0.4379 - val_accuracy: 0.8472\n",
            "Epoch 7/10\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.1444 - accuracy: 0.9485 - val_loss: 0.4271 - val_accuracy: 0.8426\n",
            "Epoch 8/10\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.1096 - accuracy: 0.9611 - val_loss: 0.4743 - val_accuracy: 0.8356\n",
            "Epoch 9/10\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.0859 - accuracy: 0.9694 - val_loss: 0.5086 - val_accuracy: 0.8410\n",
            "Epoch 10/10\n",
            "391/391 [==============================] - 11s 29ms/step - loss: 0.0775 - accuracy: 0.9735 - val_loss: 0.5626 - val_accuracy: 0.8366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3ff0a51f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foFPHmf9k5wj"
      },
      "source": [
        "*) There is overfit in the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "209-eLscPkAI"
      },
      "source": [
        "##Using Pre-Trained Embedding(Glove model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBpZmVarPiqM"
      },
      "source": [
        "import gensim.downloader as api"
      ],
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yDBHuOPPjBq"
      },
      "source": [
        "glove_model = api.load('glove-wiki-gigaword-50')"
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_V8rQ6P8PjFl",
        "outputId": "96a60358-a7f3-4add-a864-c526764389b7"
      },
      "source": [
        "glove_model.vectors.shape"
      ],
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9t8ZHUUPjHH",
        "outputId": "01a9fe03-966b-4ad9-d45d-b0cea8a2fc32"
      },
      "source": [
        "glove_model['great']"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.026567,  1.3357  , -1.028   , -0.3729  ,  0.52012 , -0.12699 ,\n",
              "       -0.35433 ,  0.37824 , -0.29716 ,  0.093894, -0.034122,  0.92961 ,\n",
              "       -0.14023 , -0.63299 ,  0.020801, -0.21533 ,  0.96923 ,  0.47654 ,\n",
              "       -1.0039  , -0.24013 , -0.36325 , -0.004757, -0.5148  , -0.4626  ,\n",
              "        1.2447  , -1.8316  , -1.5581  , -0.37465 ,  0.53362 ,  0.20883 ,\n",
              "        3.2209  ,  0.64549 ,  0.37438 , -0.17657 , -0.024164,  0.33786 ,\n",
              "       -0.419   ,  0.40081 , -0.11449 ,  0.051232, -0.15205 ,  0.29855 ,\n",
              "       -0.44052 ,  0.11089 , -0.24633 ,  0.66251 , -0.26949 , -0.49658 ,\n",
              "       -0.41618 , -0.2549  ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azdvy2etPjIM"
      },
      "source": [
        "#Initialize embedding matrix for our dataset with 10000+1 rows (1 for padding word)\n",
        "#and 50 columns (as embedding size is 50)\n",
        "embedding_matrix = np.zeros((vocab_size + 1, 50))"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFTzxEDRYyl3"
      },
      "source": [
        "for word, i in sorted(word_index.items(),key=lambda x:x[1]):\n",
        "    if i > (vocab_size+1):\n",
        "        break\n",
        "    try:\n",
        "        embedding_vector = glove_model[word] #Reading word's embedding from Glove model for a given word\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9W52RcpYyoN",
        "outputId": "03e0d991-0f0d-4dc0-eca7-e3815752c940"
      },
      "source": [
        "embedding_matrix[155]"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.14751001,  0.55555999,  1.07640004,  0.044167  ,  0.49217001,\n",
              "        0.31183001, -0.62123001, -0.28246   , -0.45550001, -0.37761   ,\n",
              "       -0.23383   , -0.75712001, -0.19904   , -0.19379   ,  1.16320002,\n",
              "       -0.56375998, -0.49566001, -0.19437   , -1.49870002,  0.1349    ,\n",
              "        0.56518   , -0.15299   ,  1.12220001,  0.11022   , -0.59064001,\n",
              "       -0.7489    ,  0.77516001, -0.62996   ,  0.18706   , -0.16483   ,\n",
              "        3.74780011,  0.51148999, -0.19912   ,  0.46902999,  0.69338   ,\n",
              "       -0.20723   ,  0.47422999,  0.22966   ,  0.53956002, -0.12704   ,\n",
              "       -0.29328999, -0.15497001,  0.89543998, -0.33169001, -0.4892    ,\n",
              "        0.29824999, -0.10244   , -0.3635    ,  0.12941   ,  0.18798   ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2iJAOQhaXw-"
      },
      "source": [
        "##Building Model using pre trained embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUNiCWHJYyqa"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = Sequential()"
      ],
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s30PARW4YytZ"
      },
      "source": [
        "model.add(Embedding(vocab_size + 1, #Vocablury size\n",
        "                                    50, #Embedding size\n",
        "                                    weights=[embedding_matrix],\n",
        "                                    trainable=False,\n",
        "                                    input_length=max_length) #Number of words in each review\n",
        "          )"
      ],
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6GsnTFsagP6"
      },
      "source": [
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(130)) #RNN State - size of cell state and hidden state\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))"
      ],
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTkqm2mfagSs"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tclrBd77oFUB"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', patience = 5)\n",
        "checkpoint= ModelCheckpoint('/content/drive/MyDrive/sequence.h5',save_best_only=True, monitor='val_accuracy',mode='max', verbose=1)"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43rDJRn_Yx1P",
        "outputId": "0c15a72c-13b4-49fa-a57d-db0d61725c47"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 250, 50)           500050    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 250, 50)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 130)               94120     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 130)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 131       \n",
            "=================================================================\n",
            "Total params: 594,301\n",
            "Trainable params: 94,251\n",
            "Non-trainable params: 500,050\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz8d76KCoiPe",
        "outputId": "93e24dd8-4619-4749-a8fe-6c965717ef26"
      },
      "source": [
        "model.output"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dense')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m__9tAFYa4Hs",
        "outputId": "88830246-853c-4c4d-c34d-f422e6ea8588"
      },
      "source": [
        "model.fit(X_train,y_train,epochs=25,batch_size=32,validation_data=(X_test, y_test), callbacks = [checkpoint])"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "782/782 [==============================] - 18s 21ms/step - loss: 0.6933 - accuracy: 0.5243 - val_loss: 0.6837 - val_accuracy: 0.5583\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.55828, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 2/25\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.6840 - accuracy: 0.5508 - val_loss: 0.6743 - val_accuracy: 0.5773\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.55828 to 0.57728, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 3/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.6766 - accuracy: 0.5684 - val_loss: 0.6745 - val_accuracy: 0.5749\n",
            "\n",
            "Epoch 00003: val_accuracy did not improve from 0.57728\n",
            "Epoch 4/25\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.6572 - accuracy: 0.6003 - val_loss: 0.6513 - val_accuracy: 0.6104\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.57728 to 0.61040, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 5/25\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.6270 - accuracy: 0.6451 - val_loss: 0.6124 - val_accuracy: 0.6637\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.61040 to 0.66368, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 6/25\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.5977 - accuracy: 0.6755 - val_loss: 0.6045 - val_accuracy: 0.6678\n",
            "\n",
            "Epoch 00006: val_accuracy improved from 0.66368 to 0.66780, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 7/25\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.5678 - accuracy: 0.7022 - val_loss: 0.6545 - val_accuracy: 0.6924\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.66780 to 0.69236, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 8/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.5415 - accuracy: 0.7260 - val_loss: 0.5364 - val_accuracy: 0.7242\n",
            "\n",
            "Epoch 00008: val_accuracy improved from 0.69236 to 0.72420, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 9/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.5185 - accuracy: 0.7418 - val_loss: 0.5192 - val_accuracy: 0.7408\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.72420 to 0.74076, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 10/25\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.4886 - accuracy: 0.7595 - val_loss: 0.5244 - val_accuracy: 0.7344\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.74076\n",
            "Epoch 11/25\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.4674 - accuracy: 0.7750 - val_loss: 0.5052 - val_accuracy: 0.7681\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.74076 to 0.76808, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 12/25\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.4438 - accuracy: 0.7926 - val_loss: 0.4920 - val_accuracy: 0.7586\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.76808\n",
            "Epoch 13/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.4195 - accuracy: 0.8066 - val_loss: 0.4732 - val_accuracy: 0.7716\n",
            "\n",
            "Epoch 00013: val_accuracy improved from 0.76808 to 0.77160, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 14/25\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.4083 - accuracy: 0.8120 - val_loss: 0.4752 - val_accuracy: 0.7794\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.77160 to 0.77940, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 15/25\n",
            "782/782 [==============================] - 16s 21ms/step - loss: 0.3844 - accuracy: 0.8264 - val_loss: 0.4682 - val_accuracy: 0.7814\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.77940 to 0.78140, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 16/25\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3645 - accuracy: 0.8366 - val_loss: 0.4639 - val_accuracy: 0.7840\n",
            "\n",
            "Epoch 00016: val_accuracy improved from 0.78140 to 0.78404, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 17/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.3550 - accuracy: 0.8430 - val_loss: 0.4767 - val_accuracy: 0.7857\n",
            "\n",
            "Epoch 00017: val_accuracy improved from 0.78404 to 0.78572, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 18/25\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.3358 - accuracy: 0.8537 - val_loss: 0.4923 - val_accuracy: 0.7825\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.78572\n",
            "Epoch 19/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.3251 - accuracy: 0.8556 - val_loss: 0.5465 - val_accuracy: 0.7574\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.78572\n",
            "Epoch 20/25\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.3089 - accuracy: 0.8634 - val_loss: 0.4924 - val_accuracy: 0.7772\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.78572\n",
            "Epoch 21/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.2990 - accuracy: 0.8704 - val_loss: 0.4857 - val_accuracy: 0.7909\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.78572 to 0.79092, saving model to /content/drive/MyDrive/sequence.h5\n",
            "Epoch 22/25\n",
            "782/782 [==============================] - 15s 20ms/step - loss: 0.2906 - accuracy: 0.8728 - val_loss: 0.4973 - val_accuracy: 0.7852\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.79092\n",
            "Epoch 23/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.2818 - accuracy: 0.8778 - val_loss: 0.5735 - val_accuracy: 0.7578\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.79092\n",
            "Epoch 24/25\n",
            "782/782 [==============================] - 17s 21ms/step - loss: 0.2745 - accuracy: 0.8829 - val_loss: 0.5113 - val_accuracy: 0.7881\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.79092\n",
            "Epoch 25/25\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.2604 - accuracy: 0.8868 - val_loss: 0.5360 - val_accuracy: 0.7788\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.79092\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f30078b0c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjLCJWtuwt9T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ6IFe1ewt_6"
      },
      "source": [
        "#Predicting a value using best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qiZyUKzGa53H"
      },
      "source": [
        "Best_model = tf.keras.models.load_model('/content/drive/MyDrive/sequence.h5')"
      ],
      "execution_count": 256,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5fgn0AEa6Bk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a43a5de1-f959-43df-9365-9c77d24dbdc6"
      },
      "source": [
        "print(X_test[563])"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    1   14\n",
            "   20    9    6 1557  991    5    2   47   32    4 9574  383  519 6141\n",
            "    2    5    6 9093  969   15 2282  210  473   21  115  188   14    9\n",
            "    2  356    2 6553  405    2    5 6339    9   44  107 3008    2  773\n",
            "    4    5    4  701    7    4    2  126  188  367  126  237    2    2\n",
            "  336 5822 6498    2  336   11    4 6480  970  107 3008    2 2306  972\n",
            "  366    2    5 6339  169  283  119  295    5   54  257  499  842    7\n",
            "   14  541 5010    9    4  222   15  571  422    2    5 6339    9    4\n",
            " 6553  356    2   34  451  182 1876 2413 1335 4668    4 9093  969   86\n",
            "  792   22    5   82   47   86 6553 1267   51   26   25 1064   18  150\n",
            "  140   46    5  851    4   20   10   10  158  158   10   10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gca6O-L1srav"
      },
      "source": [
        "decoded_review = ' '.join([reverse_word_index.get(i-3,'') for i in X_test[563]]) "
      ],
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "OdtcLVcFsyM3",
        "outputId": "757b3cd5-6faa-4277-e2fd-0da37b3e3a57"
      },
      "source": [
        "decoded_review"
      ],
      "execution_count": 259,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'                                                                                                               this movie is a absolute masterpiece and  has all the kinky sex car crashes  and a penis monster that shakespeare always wanted but never got this is  classic  troma style  and juliet is about two rival  named the and the non of the  ever got along ever since   father screwed monty  father in the filmmaking business two rival  grow apart until  and juliet find true love together and when each side hear of this blood shed is the least that happens yes  and juliet is the troma classic  by fans world wide witness harry balls the penis monster first feature film and also has first troma appearance what are you waiting for now go out and rent the movie br br 10 10 br br'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 259
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZD6BuT4BunrH"
      },
      "source": [
        "to_predict = np.array(X_test[563])"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l8g3dmpy5Lq",
        "outputId": "5abd5e1d-efba-4d26-8acb-9f8526b859fa"
      },
      "source": [
        "np.round(np.average(Best_model.predict(to_predict))) ## prediction of review at 563"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH2NY-z2zKp8",
        "outputId": "47355a23-5815-4c4c-f7b0-259d65fb99a7"
      },
      "source": [
        "y_test[563] ##original rating"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJQSHz4Cvykk"
      },
      "source": [
        "predicted = np.round(Best_model.predict(X_test))"
      ],
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8hvbHeltZEF",
        "outputId": "53b48eb7-b41b-4fd1-b777-e767de6d96e0"
      },
      "source": [
        "predicted.shape"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKjS5CH2a6Eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07d5de67-e2be-4289-c0bb-a85ee2178759"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, predicted))"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.80      0.79     12500\n",
            "           1       0.80      0.78      0.79     12500\n",
            "\n",
            "    accuracy                           0.79     25000\n",
            "   macro avg       0.79      0.79      0.79     25000\n",
            "weighted avg       0.79      0.79      0.79     25000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmhkXUfywmG6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}